##To install docker
brew install docker

K8s Architecture:
Node - it is a machine physical or virtual machine on which k8s is installed it is a worker machine and this is where 
the containers will be launched
Also known as Minion

Problem - what if node fails ?
Ans - the application on that node also fails
Soln - have multiple Node or Cluster

What is Cluster?
It is a group on Node .. or a set of Node and on each node your application is runing
it also helps in load sharing among different nodes

Problem - who will manage this cluster means who will decide how many node are up and report when a node fails then
how it move workload from one node to other
Soln- Master it is just another node with configuration information and its responsible for orchestration of container on
the worker nodes.

When you install Kubernetes on a System, you are actually installing the following
components. An API Server. An ETCD service. A kubelet service. A Container Runtime,
Controllers and Schedulers.
The API server acts as the front-end for kubernetes. The users, management devices,
Command line interfaces all talk to the API server to interact with the kubernetes
cluster.
Next is the ETCD key store. ETCD is a distributed reliable key-value store used by
kubernetes to store all data used to manage the cluster. Think of it this way, when you
have multiple nodes and multiple masters in your cluster, etcd stores all that
information on all the nodes in the cluster in a distributed manner. ETCD is
responsible for implementing locks within the cluster to ensure there are no conflicts
between the Masters.
The scheduler is responsible for distributing work or containers across multiple
nodes. It looks for newly created containers and assigns them to Nodes.
28
The controllers are the brain behind orchestration. They are responsible for noticing
and responding when nodes, containers or endpoints goes down. The controllers
makes decisions to bring up new containers in such cases.
The container runtime is the underlying software that is used to run containers. In our
case it happens to be Docker.
And finally kubelet is the agent that runs on each node in the cluster. The agent is
responsible for making sure that the containers are running on the nodes as
expected.

Ques - How One become master and other become server?
Ans - To be a Master you need following powers
   kub-apiserver 
   etcd
   controller
   scheduler
   The worker node (or minion) as it is also known, is were the containers are hosted. 
   To be a worker you need
    kubelet - that is responsible for interacting with the master to provide health information of the worker node and carry out
    actions requested by the master on the worker nodes. 
    Controller Runtime - its run docker container here we use DOCKER
    
    
Setup K8s
  brew install kubectl
  Download VirtualBox @ virtualbox.org
  brew cask install minikube
  minikube start
  minikube status
  
  Q: What is Minikube
  
  
  Q:What is POD
  
  in k8s we want do deploy our applications into worker nodes form of container in various nodes but containers cant be deployed directly into 
  worker nodes they need to be encapsulated in k8 objects knows as POD
  POD is smallest instance in k8s
  
  Now Lets suppose you have a single instance of your application running inside docker container encapslated inside POD in a single NODE
  what if Load increase -> Would you add mulitiple instance of application inside same pod
  NO POD follows ONE-ONE relationship which means that ONE POD ->ONE Container -> One instance of application instead you will
  create another pod within same node 
  so 1 Node= M*Pods where M is limit of a maxmium POD a node can handle
     1 Pod = 1 Container
     1 Container = Single Instace of application
     
  what if M reaches maximum limit you will add more nodes
  
  1 Kubernetes Cluster = N Nodes
  
But sometimes you might have a scenario were you have a helper container,
that might be doing some kind of supporting task for our web application such as
processing a user entered data, processing a file uploaded by the user etc. and you
want these helper containers to live along side your application container.


How To Deploy PODS
 kubectl run 
 this command deploy the docker container by creating a POD menas that it first
 create a POD and then deploy docker image from it
 Q.Where it get the image?.
 A.form docker hub where various application images are stored
 ex: kubectl run ngnix --image nginx
 Q.how we know list of pods and its detail
 kubectl get pods
 kubectl describe pods
 kubectl get pods -o wide - describe its IP address assigned to it note that each pods gets its own IP
  
 Q.Expose ngnix App Outside of the Cluster in a URL
 
 Summarize What we learnt:
 
A Pod is a Kubernetes abstraction that represents a group of one or more application containers (such as Docker or rkt) and some shared resources for those containers. Those resources include:
Shared storage, as volumes.
Networking, as a unique cluster IP address.
Information about how to run each container, such as the container image version or specific ports to use.

A Pod always runs on a Node. As discussed earlier, Node is a nothing but a worker machine in Kubernetes and may be either a virtual or a physical machine, depending on the cluster. Each Node is managed by the Master. A Node can have multiple pods, and the Kubernetes master automatically handles scheduling the pods across the Nodes in the cluster. The Master’s automatic scheduling takes into account the available resources on each Node.

Every Kubernetes Node runs at least:

kubelet – responsible for communication between the Kubernetes Master and the Nodes
Container runtime (Docker, rkt)

Here are some useful kubectl commands:

kubectl get– list resources
kubectl describe– show detailed information about a resource
kubectl logs– print the logs from a container in a pod
kubectl exec– execute a command on a container in a pod
kubectl delete pod pod-name


YAML in k8s
apiVersion: v1
Kind: Pod
metadata:
   name: myapp-pod
   labels:
      app: myapp
spec:

apiVersion:- This is the version of the kubernetes API we’re using to create the object. 
Depending on what we are trying to create we must use the RIGHT apiVersion. For now since we are working on
PODs, we will set the apiVersion as v1. Few other possible values for this field are
apps/v1beta1, extensions/v1beta1 etc
=========================================================
Kind- refers to the type of object we are trying to create, which in
this case happens to be a POD. So we will set it as Pod. Some other possible values
here could be ReplicaSet or Deployment or Service,
==========================================================
Metadata:- The metadata is data about the object like its name, labels etc.
As you can see unlike the first two were you specified a string value, this, is in the
form of a dictionary. So everything under metadata is intended to the right a little bit
and so names and labels are children of metadata.
===========================================================
SPEC:- Depends on the object we are going to create, this is were we provide additional information to
kubernetes pertaining to that object.Spec is a dictionary so add a property under it called containers, which is a list
or an array. The reason this property is a list is because the PODs can have multiple
containers within them

Note there are 4 Kind in k8s
Kind              Versions
POD                  v1
SERVICE              v1
REPLICASET           apps/v1
DEPLOYMENT           apps/v1   


You can create yaml online on this cool site https://codebeautify.org/yaml-validator

apiVersion: v1
Kind: Pod
metadata: 
    name: myapp-pod
    labels:
        app: myapp
spec: 
    containers: 
        - name: nginx-container
          image: nginx
          
========================================================================
Controllers are the brain behind Kubernetes.
They are processes that monitor kubernetes objects and respond accordingly
          
Replication Center -> why we need it
Reason 1
Let us assume that we have a single POD running our application. What if for some
reason, our application crashes and the POD fails? Users will no longer be able to
access our application. To prevent users from losing access to our application, we
would like to have more than one instance or POD running at the same time. That
way if one fails we still have our application running on the other one. The replication
controller helps us run multiple instances of a single POD in the kubernetes cluster
thus providing High Availability. 

Reason 2
we need replication controller is to create multiple PODs to share the
load across them.
For example, in this simple scenario we have a single POD serving
a set of users. When the number of users increase we deploy additional POD to
balance the load across the two pods. If the demand further increases and If we
were to run out of resources on the first node, we could deploy additional PODs
across other nodes in the cluster. As you can see, the replication controller spans
across multiple nodes in the cluster. It helps us balance the load across multiple pods
on different nodes as well as scale our application when the demand increases.


For example

apiVersion: v1
Kind: ReplicationController
metadata: 
    name: myapp-rc
    labels:
        app: myapp
        type: front-end
spec:   # spec for Replication Center
    - template: # every template is a new POD
        metadata: 
         name: myapp-pod
         labels:
            app: myapp
            type: front-end
        spec: 
            containers: 
            - name: nginx-container
              image: nginx
       - replicas: 3        
       
       
  ReplicaSet
  
  
  apiVersion: v1
Kind: ReplicaSet
metadata: 
    name: myapp-replicaset
    labels:
        app: myapp
        type: front-end
spec:   # spec for Replica Set
    - template: # every template is a new POD
        metadata: 
         name: myapp-pod
         labels:
            app: myapp
            type: front-end
        spec: 
            containers: 
            - name: nginx-container
              image: nginx
      replicas: 3    
      selector:
        matchLabels:
            type: front-end
            
  Command
  
  kuectl create -f replicaset-definiton.yml
  kubectl get replicaset
  kubectl describe replicaset
  kubectl delete replicaset myapp-replicaset
  kubectl replace -f replicaset-definition.yml
  kubectl scale -replicas=6 -f replicaset-d
  
  
  Note here carefully
    kuectl create -f replicaset-definiton.yml
    it will create n number of pods suppose n= 3
    NAME                     READY   STATUS    RESTARTS   AGE
myapp-replicaset-7pn46   1/1     Running   0          13s
myapp-replicaset-glwxj   1/1     Running   0          2m2s
myapp-replicaset-r745t   1/1     Running   0          2m2s

Q:What if I delete any one pod kubectl delete pod myapp-replicaset-7pn46
A: The replicaset will notice it will terminate this pod but as per specification it will start a
new pod so that n=3 maintained

Q:what if you create a new pod with kubectl create -f pod-def.yml with same label
A: Replica Controller will notice it and check label of pod

         if(label_of_new_pod.Equals(label_of_pod_Replicaset))
            delete_that_new_pod
            else
            create_that_new_pod

